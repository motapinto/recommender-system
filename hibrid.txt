- feature selection, feature weighting
- list combination is shit
- linear combination of ratings (and change the weights for the scores to make sense)
- measure overlap of the recommenders list (compute the difference for all users). if the degree of overlap is small its a good sign

Hybrid recommenders ----
- Stacking URM, ICM, UCM
- Combine models with same structure (all item based similaruty models)
- Combine models with different structure (user based, item based and matrix factorization)
- Combine models with different loss functions (ranking vs rating prediction)
- Which models performs better for a certain category of users (interactions)

Stacking
- concatenate URM and ICM and have a stack URM and stack ICM
- we can plug all icm together or choose which pair combines better
- weights in matrixes can become hyper-parameter
- apply weights in some matrixes have zero effect in some models
- Warning: some icms have garbage
- which users to include in the calcualtion of the similarity using feature weighting (treat users has features)

Combine models with same structure (parameters have same mearning)
- For example two user based, item based models
- More difficult in matrix factorization (not used normally)
- Simplest solution: weighted average (solutions are better for weihted avreage between 2 models)
- Normalization can be required is order of magnitude is very different
- Value range can be very different between models with different structure

Combine models with different structure
- combine models via weighted average of item scores
- for models with different loss functions we need to normalize the values
 

 add negative interactions for FM models
fill the dataset with equal number of positive and negative samples/interactions
radomnly select negative interactions for every user (more or less the same as the number of positive interactions)
can have a little more negative interaction than positive, but the value can be tuned as an hyper parameter
use SGD niormally, minimese MSE, and use early stopping, use bpr(quite complex)
ICM feature weighting
number of interactions different models
combine weights for hybrid